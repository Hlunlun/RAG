{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Byte Pair Encoding\n",
    "Since we want to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "sentence = \"FloydHub is the fastest way to build, train and deploy deep learning models. Build deep learning models in the cloud. Train deep learning models.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def calFrequency(text, char_table):\n",
    "    # 1. Split the text into words and add a suffix \"<w>\" to each word\n",
    "    words = text.split(\" \")\n",
    "    words_with_sfx = [word + \"<w>\" for word in words]\n",
    "\n",
    "    # 2. Calculate word frequency using Counter\n",
    "    word_freq = Counter(words_with_sfx)\n",
    "\n",
    "    # 3. Calculate character frequency while treating '<w>' as a single character\n",
    "    text_with_sfx = \" \".join(words_with_sfx)  # Join words with suffix \"<w>\"\n",
    "\n",
    "    # Create a regex pattern that treats each character in char_table as a single unit\n",
    "    re_sub_list = '|'.join(re.escape(char) for char in char_table)\n",
    "    print(re_sub_list)\n",
    "    # Find all characters, treating '<w>' and other defined characters as units\n",
    "    characters = re.findall(fr'({re_sub_list}|[^ ])', text_with_sfx)  # Use [^\\s] to match non-whitespace characters\n",
    "    char_freq = Counter(characters)\n",
    "\n",
    "    # 4. Convert the word and character frequency into pandas DataFrames (tables)\n",
    "    word_freq_table = pd.DataFrame(word_freq.items(), columns=['Word', 'Frequency'])\n",
    "    char_freq_table = pd.DataFrame(char_freq.items(), columns=['Character', 'Frequency'])\n",
    "\n",
    "    # 5. Sort the tables by frequency in descending order\n",
    "    word_freq_table = word_freq_table.sort_values(by='Frequency', ascending=False)\n",
    "    char_freq_table = char_freq_table.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "    # 6. Return the tables\n",
    "    return word_freq_table, char_freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep word table\n",
    "until size of words table = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<w>\n",
      "   Character  Frequency\n",
      "8        <w>         24\n",
      "13         e         16\n",
      "4          d         12\n",
      "1          l         11\n",
      "19         n         10\n",
      "9          i          9\n",
      "15         a          8\n",
      "2          o          7\n",
      "11         t          6\n",
      "10         s          6\n",
      "18         r          5\n",
      "6          u          4\n",
      "20         p          4\n",
      "21         g          3\n",
      "23         .          3\n",
      "22         m          3\n",
      "3          y          3\n",
      "7          b          2\n",
      "12         h          2\n",
      "24         B          1\n",
      "25         c          1\n",
      "0          F          1\n",
      "17         ,          1\n",
      "16         w          1\n",
      "14         f          1\n",
      "5          H          1\n",
      "26         T          1\n",
      "<w>|de\n",
      "<w>|de|ln\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17520\\2433802665.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Expanding character pairs until the desired dictionary size is reached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_freq_table\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdict_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mchar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar_freq_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Character\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchar2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mchar1\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mchar2\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mchar2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mchar1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# print(f'Iter: {i} \\n Best pair: {pair} \\n Tokens: {char_freq_table} \\n Numbers of tokens: {len(char_freq_table)}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\CSSA\\anaconda3\\envs\\genai\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\CSSA\\anaconda3\\envs\\genai\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1725\u001b[0m                 \u001b[1;34m\"Consider using .loc for automatic alignment.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             )\n\u001b[0;32m   1727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1729\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\CSSA\\anaconda3\\envs\\genai\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1761\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1765\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\CSSA\\anaconda3\\envs\\genai\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m   4365\u001b[0m         \u001b[0mSlicing\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0malways\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4366\u001b[0m         \"\"\"\n\u001b[0;32m   4367\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4368\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4369\u001b[1;33m         \u001b[0mnew_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4370\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict_size = 10\n",
    "char_table = ['<w>']\n",
    "word_freq_table, char_freq_table = calFrequency(sentence, char_table)\n",
    "print(char_freq_table)\n",
    "i=0\n",
    "\n",
    "# Expanding character pairs until the desired dictionary size is reached\n",
    "while len(char_freq_table) != dict_size:\n",
    "\n",
    "    char1, char2 = char_freq_table.iloc[1:3][\"Character\"]\n",
    "    pair = char1 + char2 if char1<char2 else char2+char1\n",
    "    # print(f'Iter: {i} \\n Best pair: {pair} \\n Tokens: {char_freq_table} \\n Numbers of tokens: {len(char_freq_table)}')\n",
    "\n",
    "    if pair not in char_table:  # Avoid duplicates\n",
    "        char_table.append(pair)  # Use add to update the set\n",
    "        word_freq_table, char_freq_table = calFrequency(sentence, char_table)\n",
    "\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Character  Frequency\n",
      "8        <w>         24\n",
      "1          l         11\n",
      "19         n         10\n",
      "9          i          9\n",
      "13         e          9\n",
      "15         a          8\n",
      "2          o          7\n",
      "20        de          7\n",
      "11         t          6\n",
      "10         s          6\n",
      "4          d          5\n",
      "18         r          5\n",
      "21         p          4\n",
      "6          u          4\n",
      "24         .          3\n",
      "22         g          3\n",
      "23         m          3\n",
      "3          y          3\n",
      "12         h          2\n",
      "7          b          2\n",
      "25         B          1\n",
      "26         c          1\n",
      "0          F          1\n",
      "14         f          1\n",
      "17         ,          1\n",
      "16         w          1\n",
      "5          H          1\n",
      "27         T          1\n"
     ]
    }
   ],
   "source": [
    "print(char_freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge #1: ('d', 'e')\n",
      "Merge #2: ('i', 'n')\n",
      "Merge #3: ('l', 'o')\n",
      "Merge #4: ('de', 'e')\n",
      "Merge #5: ('dee', 'p')\n",
      "Merge #6: ('l', 'e')\n",
      "Merge #7: ('le', 'a')\n",
      "Merge #8: ('lea', 'r')\n",
      "Merge #9: ('lear', 'n')\n",
      "Merge #10: ('learn', 'in')\n",
      "Merge #11: ('learnin', 'g')\n",
      "Merge #12: ('m', 'o')\n",
      "Merge #13: ('mo', 'de')\n",
      "Merge #14: ('mode', 'l')\n",
      "Merge #15: ('model', 's')\n",
      "Merge #16: ('lo', 'y')\n",
      "Merge #17: ('t', 'h')\n",
      "Merge #18: ('th', 'e')\n",
      "Merge #19: ('s', 't')\n",
      "Merge #20: ('b', 'u')\n",
      "\n",
      "Final vocabulary:\n",
      "f loy d h u b: 1\n",
      "i s: 1\n",
      "the: 2\n",
      "f a st e st: 1\n",
      "w a y: 1\n",
      "t o: 1\n",
      "bu i l d ,: 1\n",
      "t r a in: 2\n",
      "a n d: 1\n",
      "de p loy: 1\n",
      "deep: 3\n",
      "learning: 3\n",
      "models .: 2\n",
      "bu i l d: 1\n",
      "models: 1\n",
      "in: 1\n",
      "c lo u d .: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i], symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "# Initial setup\n",
    "sentence = \"FloydHub is the fastest way to build, train and deploy deep learning models. Build deep learning models in the cloud. Train deep learning models.\"\n",
    "words = sentence.split()\n",
    "vocab = defaultdict(int)\n",
    "\n",
    "# Tokenize the sentence\n",
    "for word in words:\n",
    "    tokenized_word = ' '.join(word.lower())\n",
    "    vocab[tokenized_word] += 1\n",
    "\n",
    "num_merges = 20\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    print(f\"Merge #{i+1}: {best}\")\n",
    "\n",
    "print(\"\\nFinal vocabulary:\")\n",
    "for word, freq in vocab.items():\n",
    "    print(f\"{word}: {freq}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
